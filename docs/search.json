[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Study Resources",
    "section": "",
    "text": "各種有用或有趣的網路學習資料彙整。"
  },
  {
    "objectID": "resources.html#time-series",
    "href": "resources.html#time-series",
    "title": "Study Resources",
    "section": "Time series",
    "text": "Time series\nForecasting: Principles and Practice (Using R)\n\nby Rob J Hyndman, George Athanasopoulos\nForecasting: Principles and Practice"
  },
  {
    "objectID": "resources.html#data-mining",
    "href": "resources.html#data-mining",
    "title": "Study Resources",
    "section": "Data mining",
    "text": "Data mining\nIntroduction to Data Mining (Using R)\n\nby Pang-Ning Tan, Michael Steinbach, Anuj Karpatne and Vipin Kumar\nIntroduction to Data Mining\n\nText Mining with R\n\nby Julia Silge and David Robinson\nText Mining with R"
  },
  {
    "objectID": "resources.html#nlp",
    "href": "resources.html#nlp",
    "title": "Study Resources",
    "section": "NLP",
    "text": "NLP\nStanford NLP Group\n\nIncluding slides and notes\nCS224N: Natural Language Processing with Deep Learning"
  },
  {
    "objectID": "resources.html#computer-science",
    "href": "resources.html#computer-science",
    "title": "Study Resources",
    "section": "Computer science",
    "text": "Computer science\nOS note\n\nA note about OS, including Process, Memory, File System, and more.\nhttps://blog.d0ngy3.com/p/os/"
  },
  {
    "objectID": "posts/pytorch3/pytorch3.html",
    "href": "posts/pytorch3/pytorch3.html",
    "title": "重新認識pytorch(3)",
    "section": "",
    "text": "LSTM（Long Short-Term Memory）模型是 RNN 的延伸，主要目的在於改善 RNN 梯度爆炸以及長期依賴的問題。\n具體來說，一般結構簡單的 RNN 使用的激勵函數為 Sigomid、tah，在沒有記憶性質的 NN 裡最多也只能疊6層 layers，否則在反向傳遞誤差時，誤差會隨著層數增加而減少，無法有效更新權重，有記憶性質的 RNN 在反向傳遞的誤差還會受到序列(例如從 \\(t+1\\) 到 \\(t\\))的影響，因此 一般 RNN 無法學習太長的 series data。\n要改善 RNN 的問題，一般會朝兩個方向改進：使用更複雜的模型結構，或是與其他模型結合組成混合式深度學習。\nLSTM 就是採前者的作法，使得他可以學習長期 series data，代價是，他的結構複雜，執行速度也拖慢很多。一個 ep"
  },
  {
    "objectID": "posts/pytorch3/pytorch3.html#遺忘門",
    "href": "posts/pytorch3/pytorch3.html#遺忘門",
    "title": "重新認識pytorch(3)",
    "section": "遺忘門",
    "text": "遺忘門\n遺忘門的作用是決定甚麼時候需要把以前的狀態忘記。LSTM 的遺忘門主要由三部分組成：\n\n輸入（\\(x_t\\)）：當前時刻的輸入。\n隱藏狀態（\\(h_t\\) − \\(h_{t−1}\\)）：前一時間步的隱藏狀態。\n遺忘門的激勵函數：決定了多少先前的記憶被丟棄。\n\n所以寫成數學式為：\n\\(f_t = \\sigma ( W_f \\cdot [h_{t-1}, x_t] + b_f )\\)\n其中：\n\n\\(f_t\\)：遺忘門的輸出結果\n\\(\\sigma\\)：激勵函數\n\\(b_f\\)：遺忘門的 bais"
  },
  {
    "objectID": "posts/pytorch3/pytorch3.html#輸入門",
    "href": "posts/pytorch3/pytorch3.html#輸入門",
    "title": "重新認識pytorch(3)",
    "section": "輸入門",
    "text": "輸入門\n輸入門有兩個功能，一個是找到需要更新的細胞狀態，另一個是把需要更新的資訊更新到細胞狀態裡。具體而言數學式為：\n\n\\(i_t = \\sigma (W_i \\cdot [h_{t-1},x_t] + b_i)\\)\n\\(\\hat C_t = \\tanh (W_C \\cdot [h_{t-1},x_t] + b_C)\\)\n\n其中：\n\n\\(i_t\\)︰要更新的細胞狀態\n\\(h_{t-1}\\)︰前一個時間點的模型輸出\n\\(W_i\\)：計算 \\(i_t\\) 的權重\n\\(W_C\\)：計算 \\(\\hat C_t\\) 的權重\n\\(b_i\\)：計算 \\(\\hat C_t\\)\n\n當遺忘門找到需要忘記的資訊\\(f_t\\)時，會將其與舊的狀態相乘，然後再與輸入門產生的 \\(i_t \\times \\hat C_{t-1}\\)相加，使細胞獲得新的資訊，完成細胞狀態的更新，數學式為：\n\\(C_t = f_t \\times C_{t-1} + i_t \\times \\hat C_t\\)"
  },
  {
    "objectID": "posts/pytorch3/pytorch3.html#輸出門",
    "href": "posts/pytorch3/pytorch3.html#輸出門",
    "title": "重新認識pytorch(3)",
    "section": "輸出門",
    "text": "輸出門\n輸出門會透過一個啟動函數層來確定哪部份的資訊要被輸出，接著決定模型在特定時間點 \\(t\\) 的數學結果，具體數學式如下：\n\n\\(o_t = \\sigma (W_o \\cdot [h_{t-1},x_t] + b_o)\\)\n\\(h_t = o_t \\times (C_t)\\)"
  },
  {
    "objectID": "posts/pytorch3/pytorch3.html#模型定義",
    "href": "posts/pytorch3/pytorch3.html#模型定義",
    "title": "重新認識pytorch(3)",
    "section": "模型定義",
    "text": "模型定義\nLSTM 模型的結構雖然複雜，但在 pytorch 裡的語法結構與普通的 NN 差不多。只是本次的課題要處理減法算出的數字的二進位版本，輸出會是由 0 與 1 組成的序列，比較特殊，因此模型結構也以此設計。先來看看一般 LSTM 模型的架構在pythorch中是什麼樣子，以下是一個是個通用範例：\nimport torch\nimport torch.nn as nn\n\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size=1, hidden_size=128, output_size=1):\n        super(LSTMModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n            out, _ = self.lstm(x)    # [batch, seq_len, hidden_size]\n            out = self.fc(out)       # [batch, seq_len, output_size]\n            return out\n可以看到與之前看到的 NN 模型類似，都需要用一個 class 包覆，也需要設定 input、output、hidden數，以及正向傳遞。\n由於本次課題的特殊性，本次使用的模型多了一個 self.sigmoid = nn.Sigmoid()，這是為了跟後續 loss function 的設定 BCELoss()配合。模型設定如下：\n\nimport torch.nn as nn\n\nclass LSTMSubtractor(nn.Module):\n    def __init__(self, input_size=2, hidden_size=32, output_size=1):\n        super(LSTMSubtractor, self).__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)  # output: (batch, seq_len, hidden)\n        out = self.fc(lstm_out)     # (batch, seq_len, 1)\n        return self.sigmoid(out)    # predict bit 0 or 1\n\n\n參數設定與模型訓練\n參數設定如下：\n接著來設定參數：\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = LSTMSubtractor().to(device)\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nEPOCHS = 100\n\n這裡要解釋 nn.BCELoss() 是什麼東西，根據 pytorch 官方文件 ，它的數學式為：\nfor all sample size \\(n\\)\n\\[\n\\ell_n = - w_n \\left[ y_n \\cdot \\log(x_n) + (1 - y_n) \\cdot \\log(1 - x_n) \\right]\n\\]\n\n\\(x_n\\)：模型輸出機率（預測值），需介於 0 與 1 之間\n\\(y_n\\)：真實值（0 或 1）\n\\(w_n\\)：逐樣本權重（若未指定權重則預設為 1）\n\n然後 \\(\\ell_n\\) 可以組成向量 \\(L = (l_1, \\dots , l_n)^T\\)，接著按照裡面的設定不同，輸出也會不同：\n\\[\\ell(x, y) =\n\\begin{cases}\n\\text{mean}(L), & \\text{if reduction='mean'} \\\\\n\\text{sum}(L), & \\text{if reduction='sum'}\n\\end{cases}\\]\n整批次資料的損失根據 reduction 的設定方式不同，被輸出為一個 scalar：\n\n'mean'（預設）：\n\\[\n\\text{loss} = \\frac{1}{N} \\sum_{n=1}^{N} \\ell_n\n\\]\n'sum'：\n\\[\n\\text{loss} = \\sum_{n=1}^{N} \\ell_n\n\\]\n'none'： 保持逐元素損失，不做處理，輸出與輸入相同\n\n由於 \\(x_n = 0\\) 或 \\(x_n = 1\\) 時會導致 \\(\\log(0)\\) 出現負無限大，PyTorch 在實作中將 log 的最小值限制為 \\(-100\\)，避免出現無限大或梯度爆炸的情況，確保訓練穩定。\n接著，我們將　epoch　(模型掃過資料的次數)設為 100，對訓練集訓練：\n\n\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n    for x_batch, y_batch in train_loader:\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device).unsqueeze(-1)  # (batch, 8, 1)\n\n        optimizer.zero_grad()\n        output = model(x_batch)\n        loss = criterion(output, y_batch)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss:.4f}\", end='\\r')\n\nEpoch 100/100, Loss: 0.0002\n\n\n定義預測函數、進行預測後，再來查看在測試集的效果：\n\ndef binary2int(binary_array):\n    \"\"\"將二進位 ndarray 轉換為十進位整數\"\"\"\n    return int(\"\".join(str(int(b)) for b in binary_array), 2)\n\n\ndef predict(model, a_int, b_int):\n    model.eval()\n    a = int2binary[a_int]\n    b = int2binary[b_int]\n    x = np.array(list(zip(a[::-1], b[::-1])), dtype=np.float32)\n    x_tensor = torch.tensor(x).unsqueeze(0).to(device)  # (1, 8, 2)\n\n    with torch.no_grad():\n        pred = model(x_tensor).squeeze().cpu().numpy()\n\n    pred_bits = np.round(pred).astype(int)[::-1]  # 反轉回原本順序\n    pred_val = sum([bit * (2 ** i) for i, bit in enumerate(pred_bits[::-1])])\n    return pred_val, pred_bits"
  },
  {
    "objectID": "posts/pytorch3/pytorch3.html#結果",
    "href": "posts/pytorch3/pytorch3.html#結果",
    "title": "重新認識pytorch(3)",
    "section": "結果",
    "text": "結果\n\ndef bits_to_int(bit_tensor):\n    \"\"\"將 bit tensor 轉為十進位整數（從低位開始）\"\"\"\n    bits = bit_tensor.int().numpy().tolist()\n    return int(\"\".join(str(b) for b in bits[::-1]), 2)  # 注意反轉\n\n\n\nError_list = []\n\nfor j in range(len(test_set)):\n    # 讀一筆\n    x, y = test_set[j]\n\n    # 拆開 a 和 b 的 bits（注意 shape 是 [seq_len, 2]）\n    a_bits = x[:, 0]\n    b_bits = x[:, 1]\n    c_bits = y\n    \n\n    # 還原整數\n    a_int = bits_to_int(a_bits)\n    b_int = bits_to_int(b_bits)\n    c_int = bits_to_int(c_bits)  \n    d = predict(model, a_int, b_int)\n    \n    # 紀錄誤差\n    error = np.abs(c_int - d[0]) \n    Error_list.append(error)     \n    # 取其中的五筆觀察\n    if j % 200 == 0: \n        # 顯示\n        print(f\"True value:　{c_int} ; {c}\")\n        print(f\"Predicted value: {d[0]} ; {d[1]}\")\n        print(f\"Predicted formula: {a_int} - {b_int} = {d[0]}\")\n        print(\"---------------\")\n\nTrue value:　62 ; [0 0 0 0 1 1 1 1]\nPredicted value: 62 ; [0 0 1 1 1 1 1 0]\nPredicted formula: 123 - 61 = 62\n---------------\nTrue value:　24 ; [0 0 0 0 1 1 1 1]\nPredicted value: 24 ; [0 0 0 1 1 0 0 0]\nPredicted formula: 118 - 94 = 24\n---------------\nTrue value:　116 ; [0 0 0 0 1 1 1 1]\nPredicted value: 116 ; [0 1 1 1 0 1 0 0]\nPredicted formula: 250 - 134 = 116\n---------------\nTrue value:　137 ; [0 0 0 0 1 1 1 1]\nPredicted value: 137 ; [1 0 0 0 1 0 0 1]\nPredicted formula: 204 - 67 = 137\n---------------\nTrue value:　185 ; [0 0 0 0 1 1 1 1]\nPredicted value: 185 ; [1 0 1 1 1 0 0 1]\nPredicted formula: 245 - 60 = 185\n---------------\n\n\n把誤差化成圖：\n\nimport matplotlib.pyplot as plt \nplt.figure(figsize=(10, 4))\nplt.plot( Error_list, label=\"Absolute Error\")\nplt.xlabel(\"Sample Index\")\nplt.ylabel(\"Error Value\")\nplt.title(\"Prediction Error per Test Sample\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n在測試集的表現非常好，順便來介紹 & 計算常用模型評估指標，RMSE。RMSE（Root Mean Squared Error）為 MSE 的平方根，是常用的模型誤差評估指標。\n\\[\n\\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2 } = \\sqrt{\\text{MSE}}\n\\]\n\nimport numpy as np\n\ntrue_vals = []\npred_vals = []\n\nfor x, y in test_set:\n    # 還原 a、b 的 bit 並轉為十進位\n    a_int = bits_to_int(x[:, 0])\n    b_int = bits_to_int(x[:, 1])\n    true_val = bits_to_int(y)\n\n    pred_val, _ = predict(model, a_int, b_int)\n\n    true_vals.append(true_val)\n    pred_vals.append(pred_val)\n\n# 轉為 numpy 陣列\ntrue_vals = np.array(true_vals)\npred_vals = np.array(pred_vals)\nerrors = np.abs(true_vals - pred_vals)\n# 計算 RMSE\nrmse = np.sqrt(np.mean((true_vals - pred_vals) ** 2))\nprint(f\"RMSE: {rmse:.4f}\")\n\nRMSE: 0.0000\n\n\n\nimport matplotlib.pyplot as plt \nplt.figure(figsize=(10, 4))\nx = [ x for x in range(501, 1001)]\nplt.plot( errors, label=\"Absolute Error\")\nplt.xlabel(\"Sample Index\")\nplt.ylabel(\"Error Value\")\nplt.title(\"Prediction Error per Test Sample\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n這裡因為誤差是 0 RMSE 想當然爾也是0囉。"
  },
  {
    "objectID": "posts/pytorch3/pytorch3.html#gru-延伸閱讀",
    "href": "posts/pytorch3/pytorch3.html#gru-延伸閱讀",
    "title": "重新認識pytorch(3)",
    "section": "GRU 延伸閱讀",
    "text": "GRU 延伸閱讀\n\nLSTM與GRU比較論文摘要"
  },
  {
    "objectID": "posts/pytorch1/pytorch1.html",
    "href": "posts/pytorch1/pytorch1.html",
    "title": "重新認識pytorch(1)",
    "section": "",
    "text": "為了研究 LSTM 與神經網路(neural network，以下簡稱 nn)，重新認識 pytorch 。"
  },
  {
    "objectID": "posts/pytorch1/pytorch1.html#定義模型及函數",
    "href": "posts/pytorch1/pytorch1.html#定義模型及函數",
    "title": "重新認識pytorch(1)",
    "section": "定義模型及函數",
    "text": "定義模型及函數\n因為只是模擬資料，我們略過區分訓練集與測試集的步驟，直接來建立模型。本次使用一個簡單的兩層nn模型LogicNet，這個模型可視作羅吉斯迴歸的延伸，只是多個隱藏層(hidden layer)的設定。一個 nn 模型中還會需要搭配損失函數，這裡配的是交叉熵損失函數(Cross-Entrop)用來做分類。\nLogicNet的模型結構與數學式分別如下：\nInput (inputdim)\n    │\n    ▼\nLinear1 ────► [Linear Layer: inputdim → hiddendim]\n    │\n    ▼\nTanh ───────► [非線性(NL): tanh]\n    │\n    ▼\nLinear2 ────► [Linear Layer: hiddendim → outputdim]\n    │\n    ▼\nOutput (logits)\n令：\n\n輸入：\\(\\mathbf{x} \\in \\mathbb{R}^{\\text{inputdim}}\\)\n第一層(Linear1)權重、偏差：\\(W_1, b_1\\)\n第二層(Linear2)權重、偏差：\\(W_2, b_2\\)\n\n那模型的輸出為：\n\\[\n\\begin{aligned}\n\\mathbf{h} &= \\tanh(W_1 \\mathbf{x} + b_1) \\quad \\text{（隱藏層輸出）} \\\\\n\\mathbf{z} &= W_2 \\mathbf{h} + b_2 \\quad \\text{（logits）} \\\\\n\\end{aligned}\n\\]\n最終輸出 \\(\\mathbf{z}\\) 是 未經 softmax 演算法 的 logits，這是為了符合 PyTorch 的 CrossEntropyLoss() 要求，因為它內部會自動做 softmax。\n\n\n\n\n\n\nsoftmax 演算法是什麼?\n\n\n\n\n\nsoftmax 本質上也屬於 activation function的一種，它能將一個含任意實數的K維向量 \\(z\\)「壓縮」到另一個K維實向量 \\(\\sigma (z)\\) ，使得每一個元素的範圍都在(0,1)之間，公式為：\n\\[\\sigma (z)_j=\\frac{e^{z_j}}{\\sum _{k=1}^{K}e^{z_{jk}}}\\]\n詳細可見wiki\n簡單來說，softmax 算出來的東西是機率。\n\n\n\n\n\n\n\n\n\n為什麼這裡 activation function 用 tanh？\n\n\n\n\ntanh 是一種非線性函數，將輸出壓在 \\([-1, 1]\\)\n適用於資料已經經過標準化（例如 make_moons 資料範圍在 ±1 內）\n也可以改用更為通用的 ReLU，它的收斂速度通常更快。不過 tanh 有時在小模型且資料差異大中表現穩定。\n\n\n\n整體建立模型的流程為：\n\n定義模型的網路結構\n將網路結構按前向傳播(forward propagation)建立\n利用架設好的介面，得到模型預測結果\n計算模型誤差，在反向傳播(back propagation)時使用\n\n程式部分我們建立可以控制input data 的 dimension、hidden dimension(=隱藏層數量)，output data 的 dimension等的模型函數。 code 如下，可另存 .py後再匯入到主程式裡：\n\nimport torch.nn as nn\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass LogicNet(nn.Module): \n    def __init__(self, inputdim, hiddendim, outputdim):\n        super(LogicNet,self).__init__()\n        self.Linear1 = nn.Linear(inputdim,hiddendim) # 連階層\n        self.Linear2 = nn.Linear(hiddendim,outputdim)\n        self.criterion = nn.CrossEntropyLoss() # 定義交叉熵\n\n    # 前向傳播\n    def forward(self, x):\n        x = self.Linear1(x) # 將資料傳入第一層\n        x = torch.tanh(x) # 做 NL\n        x = self.Linear2(x)\n        return x\n\n    def predict(self, x):\n        pred = torch.softmax(self.forward(x), dim=1)\n        return torch.argmax(pred,dim=1)\n\n    # 反向傳播\n    def getloss(self,x,y):\n        y_pred = self.forward(x)\n        loss = self.criterion(y_pred,y) # 計算loss CrossEntropy\n        return loss\n\n\n\n\n\n\n\n為什麼這裡所有函數都要包在 class 裡？\n\n\n\n\n\nPyTorch 中的所有神經網路模型都應繼承自 torch.nn.Module。這樣做的好處是：\n\n可以自動註冊所有子層（如 nn.Linear）\n支援 .to(device)、.eval()、.train() 等常用方法\n可以很簡單地使用 PyTorch 提供的訓練工具，例如 optimizer.step()、loss.backward() 等\n\n此外，從OOP的角度而言，把模型寫成一個class可以讓模型變成一個完整的物件，更易維護。\n\n\n\n這裡除了 activation function 外，還定義了 criterion，即 loss function。loss function是決定模型學習品質的關鍵，用來計算輸出值與目標值間的誤差。一般在連續的實數資料上會用 MSE ，不過在實務上會根據不同的結構、任務決定不同的 loss function ，這裡使用的是交叉熵損失函數(Cross Entropy Loss)，適用於分類問題。"
  },
  {
    "objectID": "posts/pytorch1/pytorch1.html#建立模型",
    "href": "posts/pytorch1/pytorch1.html#建立模型",
    "title": "重新認識pytorch(1)",
    "section": "建立模型",
    "text": "建立模型\n如前所述，我們現在來正式建立模型。因為模擬資料都是2維的，dimension = 2，隱藏層數量可以自行設定，這裡設定 3 個隱藏層：\n\nmodel = LogicNet(inputdim=2, hiddendim=3, outputdim =2)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01 )\n# 印出模型資訊\nprint(\"model structure and loss function/criterion: \\n\")\nprint(model)\nprint(\"optimizer is : \\n\")\nprint(optimizer)\n\nmodel structure and loss function/criterion: \n\nLogicNet(\n  (Linear1): Linear(in_features=2, out_features=3, bias=True)\n  (Linear2): Linear(in_features=3, out_features=2, bias=True)\n  (criterion): CrossEntropyLoss()\n)\noptimizer is : \n\nAdam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.01\n    maximize: False\n    weight_decay: 0\n)\n\n\n\n學習率(learning rate)\nlr = 學習率(learning rate)learning rate，代表控制模型中梯度下降的速度，它決定了每次迭代的步長，使得optimizer向損失函數的最小值前進。數值越小，模型越能訓練準確，但相對應訓練較耗時。\n學習率與模型權重間的關係為：\n新權重= 舊權重- 學習率* 梯度\n\n\n最佳化器(optimizer)\n在模型訓練的過程中，往往難以一次就將權重參數調整好，需要透過多次迭代，搭配好的最佳化策略才可以實現。這裡的最佳化策略就是一個演算法，也就是梯度下降法。梯度下降法有很多種，因此也是一個可以調整的參數。\n在 pytorch 中，在訓練模型前需要先指定一個最佳化器物件，也就是最佳化器(optimizer)。實務上經常使用Adam作為最佳化器，數學式請見此。Adam本身包含很多參數，常用的有待最佳化權重參數(固定為model.parameters())及學習率。"
  },
  {
    "objectID": "posts/pytorch1/pytorch1.html#訓練模型",
    "href": "posts/pytorch1/pytorch1.html#訓練模型",
    "title": "重新認識pytorch(1)",
    "section": "訓練模型",
    "text": "訓練模型\n在 pytorch 中，訓練模型前需先將資料轉成張量(Tensor)後再處理。\n\n張量\n張量是一種矩陣形式，可以理解成在一個大矩陣中分割出來的小矩陣。因此：\n\n0 dimension 的張量 = 純量 (Scalar)\n1 dimension 的張量 = 向量 (Vector)\n2 dimension 的張量 = 2 \\(\\times\\) 矩陣 (2 \\(\\times\\) 2 Ｍatrix)\n\n圖示如下：\n\n\n\n訓練模型與計算 loss\n回到正題，接著再訓練模型與計算 loss：\n\n## 訓練模型\n# 轉成張量\nxt = torch.from_numpy(X).type(torch.FloatTensor) # numpy to tensor\nyt =  torch.from_numpy(Y).type(torch.LongTensor)\nepochs = 1000 # 迭代次數\nlosses =[] #準備接收每一步的loss\nfor i in range(epochs):\n    loss = model.getloss(xt,yt)\n    losses.append(loss.item())\n    optimizer.zero_grad() #清空之前的梯度\n    loss.backward()\n    optimizer.step() #更新參數\n\n接著看看訓練結果：　\n\nimport matplotlib.pyplot as plt\n\nplt.plot(losses)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss Over Time')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n或者先對 loss 值做平滑處理，再視覺化，可以使某些訓練過程中產生的loss線條看起來比較平滑。這裡以moving average為例：\n\ndef moving_average(a, w=10):\n    if len(a)&lt;w:\n        return a[:]\n    return [val if idx &lt; w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n\ndef plot_losses(losses):\n    avgloss= moving_average(losses)\n    plt.figure(i)\n    plt.plot(range(len(avgloss)), avgloss, 'b--')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.show()\n\nplot_losses(losses)"
  },
  {
    "objectID": "posts/pytorch1/pytorch1.html#評估模型",
    "href": "posts/pytorch1/pytorch1.html#評估模型",
    "title": "重新認識pytorch(1)",
    "section": "評估模型",
    "text": "評估模型\naccuracy_score()是一個來自 sklearn.metrics 的函數，用來計算模型預測結果的 分類準確率（Accuracy），直觀理解為：模型預測正確的樣本數 / 全部樣本數。\n按klearn文件紀錄，詳細數學定義為：\nIf $_i$ is the predicted value of the $i$-th sample and \\(y_i\\) is the corresponding true value, then the fraction of correct predictions over \\(n_{samples}\\) samples is defined as:\n\\[\n\\text{Accuracy}(y, \\hat y) = \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}-1} \\mathbf{1}(\\hat{y}_i = y_i)\n\\]\nwhere \\(\\mathbf{1}(\\hat{y}_i = y_i)\\) is the indicator function, which equals 1 if the prediction is correct, and 0 otherwise.\ncode實際執行起來很簡單：\n\nfrom sklearn.metrics import accuracy_score\nprint(\"accuracy_score:\", accuracy_score(model.predict(xt),yt))\n\n除此之外，因為本次資料dimension只有2維，可以畫決策邊界圖看看分得如何：\n\ndef predict(x):\n    x = torch.from_numpy(x).type(torch.FloatTensor)\n    ans=model.predict(x)\n    return ans.numpy()\n\ndef plot_decision_boundary(pred_func, X, Y):\n    # 計算設定值範圍\n    x_min, x_max =X[:,0].min() - .5,X[:,0].max() + .5\n    y_min, y_max =X[:,1].min() - .5,X[:,1].max() + .5  \n    h = 0.01\n    # 生成網格矩陣\n    xx, yy=np.meshgrid(np.arange(x_min,x_max,h), np.arange(y_min,y_max,h))\n    Z = pred_func(np.c_[xx.ravel(),yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    plt.contourf(xx,yy,Z,cmap=plt.cm.Spectral)\n    arg = np.squeeze(np.argwhere(Y==0),axis=1)\n    arg2 = np.squeeze(np.argwhere(Y==1),axis=1)\n    plt.scatter(X[arg,0],X[arg,1], s=100, c='r', marker='+')\n    plt.scatter(X[arg2,0],X[arg2,1], s=100, c='b', marker='+')\n    plt.show()\nplot_decision_boundary(lambda x: predict(x), xt.numpy(),yt.numpy())\n\n\n\n\n\n\n\n\n實際執行時，nn的 node 的初始值是隨機的，每次訓練過程都是從初始值開始調節，所以每次執行完做的模型評估結果都會有些微的不同，但accuracy_score()分數整體會在一個範圍浮動，差異不大。"
  },
  {
    "objectID": "posts/pytorch1/pytorch1.html#保存模型",
    "href": "posts/pytorch1/pytorch1.html#保存模型",
    "title": "重新認識pytorch(1)",
    "section": "保存模型",
    "text": "保存模型\n通常一個模型需要長時間的訓練，所以 pytorch 可以保存模型，供下次進行預訓練或直接使用：\ntorch.save(model.state_dict(),'./model.pth')\n這個model.pth便是模型檔案。如要載入模型，則可以：\nmodel.load_state_dict(torch.load('./model.pth'))\n執行後 model 中的值將跟model.pth同步。"
  },
  {
    "objectID": "posts/jpyterbook/index.html",
    "href": "posts/jpyterbook/index.html",
    "title": "如何使用 Python jupyter-book 建立一本書",
    "section": "",
    "text": "說到 jupyter-book，可能很多人會想到 Jupyter Notebook，但這裡指的是一個 python 套件，用來建立線上書籍的工具，特別適合用於副檔名為 .ipynb 的 Jupyter Notebook 。最後產出的網站類似 gitbook 或是 bookdown 的靜態網站，適合用來寫教學、筆記或是書籍。也是在我使用 Quarto 之前考慮過的選項之一，雖然最後因為產出有點陽春、能改動的東西較少所以放棄了，但它的製作過程簡單，所以留下這個筆記，方便日後需要時可以快速上手。\n\n\n這是我的使用環境，不一定適用每個人，但截至目前為止都運作順利：\n\nIDE ： VsCode\nPython version : 3.12.5"
  },
  {
    "objectID": "posts/jpyterbook/index.html#使用環境",
    "href": "posts/jpyterbook/index.html#使用環境",
    "title": "如何使用 Python jupyter-book 建立一本書",
    "section": "",
    "text": "這是我的使用環境，不一定適用每個人，但截至目前為止都運作順利：\n\nIDE ： VsCode\nPython version : 3.12.5"
  },
  {
    "objectID": "posts/jpyterbook/index.html#安裝-jupyter-book",
    "href": "posts/jpyterbook/index.html#安裝-jupyter-book",
    "title": "如何使用 Python jupyter-book 建立一本書",
    "section": "安裝 jupyter-book",
    "text": "安裝 jupyter-book\npip install -U jupyter-book"
  },
  {
    "objectID": "posts/jpyterbook/index.html#建立一本書的骨架",
    "href": "posts/jpyterbook/index.html#建立一本書的骨架",
    "title": "如何使用 Python jupyter-book 建立一本書",
    "section": "建立一本書的骨架",
    "text": "建立一本書的骨架\n使用命令行建立一個新的書籍專案：\njupyter-book create mybook/\n這會建立一個名為 mybook/ 的資料夾，裡面包含書籍的基本結構，包括 Markdown 與 Jupyter Notebook 範例，mybook/ 亦可以自行換成其他資料夾名稱。"
  },
  {
    "objectID": "posts/jpyterbook/index.html#編輯內容",
    "href": "posts/jpyterbook/index.html#編輯內容",
    "title": "如何使用 Python jupyter-book 建立一本書",
    "section": "編輯內容",
    "text": "編輯內容\n\n從這裡開始就是在編輯時會重複執行的步驟！\n\n可以在 mybook/ 目錄中看到這些重要檔案和資料夾：\n\nmybook/_config.yml：書籍的設定（標題、主題、logo 等）\nmybook/_toc.yml：書籍目錄（控制章節順序）\nmybook/intro.md、mybook/chapters/*.ipynb：實際內容，可新增 Markdown 或 Notebook 檔案\n\n\n新增章節例子：\n\n在 mybook/ 下新增一個檔案，例如 chapter1.md\n在 _toc.yml 中加上該檔案的設定：\n\nformat: jb-book\nroot: intro\nchapters:\n  - file: chapter1"
  },
  {
    "objectID": "posts/jpyterbook/index.html#編譯網站",
    "href": "posts/jpyterbook/index.html#編譯網站",
    "title": "如何使用 Python jupyter-book 建立一本書",
    "section": "編譯網站",
    "text": "編譯網站\n在書籍資料夾中執行：\njupyter-book build mybook/\n這會自動產生靜態網站，輸出目錄為：\nmybook/_build/html/"
  },
  {
    "objectID": "posts/jpyterbook/index.html#預覽網站",
    "href": "posts/jpyterbook/index.html#預覽網站",
    "title": "如何使用 Python jupyter-book 建立一本書",
    "section": "預覽網站",
    "text": "預覽網站\n使用瀏覽器打開以下檔案即可：\nmybook/_build/html/index.html\n或用 Python 的 HTTP server 預覽：\ncd mybook/_build/html\npython -m http.server\n然後打開瀏覽器到 http://localhost:8000\n\n\n注意：如果你有修改 _toc.yml 或其他設定，必須重新編譯網站才能看到變更，不然會顯示舊的內容。\n如果編譯網站後有做刪除頁面的動作，請到 _build/html/ 資料夾刪除對應的 html，不然他不會蓋到很笨我知道。\n執行後 terminal 的 powershell 非必要請不要關閉，因為它在運行 HTTP server。需要關閉可以在 terminal 視窗 輸入 Ctrl + C 停止服務。或是另開新的 terminal 視窗來執行其他命令。"
  },
  {
    "objectID": "posts/jpyterbook/index.html#發布網站選擇性",
    "href": "posts/jpyterbook/index.html#發布網站選擇性",
    "title": "如何使用 Python jupyter-book 建立一本書",
    "section": "發布網站（選擇性）",
    "text": "發布網站（選擇性）\n可以把 _build/html 上傳到 GitHub Pages、Netlify、Vercel 等平台，或用 GitHub Actions 自動部署。"
  },
  {
    "objectID": "posts/book-review/book-review.html",
    "href": "posts/book-review/book-review.html",
    "title": "讀書筆記-數據分析的力量 Google、Uber都在用的因果關係思考法",
    "section": "",
    "text": "數據分析的力量 Google、Uber都在用的因果關係思考法\nbook information"
  },
  {
    "objectID": "posts/book-review/book-review.html#隨機對照實驗-rct",
    "href": "posts/book-review/book-review.html#隨機對照實驗-rct",
    "title": "讀書筆記-數據分析的力量 Google、Uber都在用的因果關係思考法",
    "section": "隨機對照實驗 (RCT)",
    "text": "隨機對照實驗 (RCT)\n將實驗區分為介入組跟比較組，藉由探究兩者的介入效果(Treatment Effect)，即：有介入的組-沒有介入的組的效果\n\n介入組：有受到政策/措施影響的組別\n比較組：沒有受到政策/措施影響的組別\n\n\n在商業領域，RCT = A/B test\n\n\n假設\n\n如果沒有介入(政策/措施的影響)，比較組的平均 \\(Y_C\\) 會與介入組的平均 \\(Y_T\\) 相同\n\n\n\n注意點\n\n妥善建立群組\n一定要隨機分組\n各組樣本數需充足\n\n\n\n優缺點\n優\n\n因果關係強\n分析手法與結果具透明性\n\n缺\n\n實施成本高昂"
  },
  {
    "objectID": "posts/book-review/book-review.html#rd-設計",
    "href": "posts/book-review/book-review.html#rd-設計",
    "title": "讀書筆記-數據分析的力量 Google、Uber都在用的因果關係思考法",
    "section": "RD 設計",
    "text": "RD 設計\n\n當 RCT 無法使用時使用，可將 RD 設計想成在界線附近自然發生的 RCT。\n利用自然實驗(= 猶如人工作出實驗的自然發生情況)分析\n\n\n假設\n\n如果 \\(X\\) 未在界線上變動，\\(Y\\) 就不會在界線上發生跳躍\n\n\n實務上是個不容易證實的假設\n\n\n\n注意點\n\n要先找出「界線」上，僅因一種因素(\\(X\\))發生不連續變化的情況\n需要檢驗其他因素是否也會導致 \\(Y\\) 在界線上發生跳躍，如果會，那 RD 假設就不成立，結果解釋會不準確。\n\n\n\n優缺\n優：\n\n只要不違反假設就可以證實因果關係\n實施成本比 RCT 低廉\n\n缺：\n\n只能測試在界線附近的人之因果關係，離界線很遠的人，需要加上其他假設，否則無法解釋\n\n\n\n例子\n\n南北地理界線的電價差異是否導致家庭用電量變動"
  },
  {
    "objectID": "posts/book-review/book-review.html#堆集分析bunching-analysis",
    "href": "posts/book-review/book-review.html#堆集分析bunching-analysis",
    "title": "讀書筆記-數據分析的力量 Google、Uber都在用的因果關係思考法",
    "section": "堆集分析(Bunching Analysis)",
    "text": "堆集分析(Bunching Analysis)\n一樣在 RCT 無法使用時使用，利用資料階梯狀的變化分析因果關係\n\n假設\n\n如果 \\(X\\) 並未呈階梯狀變化，\\(Y\\)分布會平滑，不會在界線上堆集。\n\n\n\n注意點\n\n評估某個呈階梯狀變化的因素是否能用於分析\n導致資料呈階梯狀變化的因素只有一個，沒有其他人\n需要分析誘因大幅變化的分界點上發生的堆集，檢驗人 or 企業對誘因變化有甚麼反應/因果關係\n\n\n\n例子\n\n汽車越大台，油耗規定是否越寬鬆\n所得稅的稅率是否影響工作方式\n\n\n\n優缺\n優：\n\n假設成立，效果便近似 RCT\n分析結果易於理解\n\n缺：\n\n只能推定分界點附近受到呈階梯狀變化誘因影響的主體\n假設更難證明成立"
  },
  {
    "objectID": "posts/book-review/book-review.html#縱橫資料分析",
    "href": "posts/book-review/book-review.html#縱橫資料分析",
    "title": "讀書筆記-數據分析的力量 Google、Uber都在用的因果關係思考法",
    "section": "縱橫資料分析",
    "text": "縱橫資料分析\n一樣在 RCT 無法使用時使用，假設政府/企業實施某項政策/措施時，有的群組有受到影響，有的沒有，此時：\n\n有受到政策/措施影響的群組為介入組\n沒有受到影響的為比較組\n\n此外也有這兩個群組實施前跟實施後不同時間點的資料，就可以做縱橫資料分析，求出介入組在沒有介入(實施某項政策/措施)時的可能效果，進而得出此項政策/措施的介入效果(=實際介入效果-沒有介入時的可能效果)\n\n假設\n平行趨勢假設：\n\n如果沒有發生介入，介入組的平均結果(\\(Y_T\\))和比較組的的平均結果(\\(Y_C\\))就會平行推移\n\n\n\n\n注意點\n主張平行趨勢假設成立需要做：\n\n蒐集介入發生以前的資料，調查介入發生之前平行趨勢假設是否存在介入組跟比較組之間\n仔細檢查介入開始後，有無其他影響因素只影響介入組跟比較組中的其中一組\n若平行趨勢假設成立，就將雙方的平均數推移化成圖表，測定介入效果的平均數\n\n\n\n例子\n\n所得稅與移民關係的因果關係\n實施景氣刺激政策是否只會增加搶購需求\n\n\n\n優缺\n優：\n\n可應用範圍比 RD 設計跟堆集分析大\n分析結果易於理解\n可分析對象跟範圍比 RD 設計跟堆集分析大，可分析主體效果\n\n缺：\n\n假設很難證明是否成立，也很難成立"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "有一天同事在我桌上放了零食，上面貼了一張便利貼，便利貼上面畫著一隻魚。所以我的部落格叫紙魚😊\n\n\n\n\n\n\n\n\n\n\n\n讀書筆記-數據分析的力量 Google、Uber都在用的因果關係思考法\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\nSide Project - 簡易預估搭乘新竹客運假日從新竹到台中的時間\n\n\n\n\n\n\n\n\n\n\n\nSep 7, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n重新認識pytorch(3)\n\n\nLSTM簡介與實作\n\n\n\n\n\n\n\n\nAug 28, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n重新認識pytorch(2)\n\n\n了解RNN\n\n\n\n\n\n\n\n\nAug 24, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n重新認識pytorch(1)\n\n\n從一個分類問題開始\n\n\n\n\n\n\n\n\nAug 21, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n使用python做離線倒數計時器\n\n\n第一次用python做exe，不會的問AI\n\n\n\n\n\n\n\n\nAug 9, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n如何使用 Python jupyter-book 建立一本書\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n使用 Quarto 建立 Blog\n\n\n第一篇文章，來分享這個部落格是怎麼建立的\n\n\n\n\n\n\n\n\nJul 23, 2025\n\n\n紙魚\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "紙魚ㄉ部落格",
    "section": "",
    "text": "來寫 Blog 吧！\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n讀書筆記-數據分析的力量 Google、Uber都在用的因果關係思考法\n\n\n\n\n\n\nreading note\n\n\n\n\n\n\n\n\n\nSep 8, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n\n\nSide Project - 簡易預估搭乘新竹客運假日從新竹到台中的時間\n\n\n\n\n\n\nside project\n\npython\n\nLSTM\n\n\n\n\n\n\n\n\n\nSep 7, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n\n\n重新認識pytorch(3)\n\n\nLSTM簡介與實作\n\n\n\nnote\n\npython\n\npytorch\n\n\n\n\n\n\n\n\n\nAug 28, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n\n\n重新認識pytorch(2)\n\n\n了解RNN\n\n\n\nnote\n\npython\n\npytorch\n\n\n\n\n\n\n\n\n\nAug 24, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n\n\n重新認識pytorch(1)\n\n\n從一個分類問題開始\n\n\n\nnote\n\npython\n\npytorch\n\n\n\n\n\n\n\n\n\nAug 21, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n\n\n使用python做離線倒數計時器\n\n\n第一次用python做exe，不會的問AI\n\n\n\npython\n\ntoys\n\n\n\n\n\n\n\n\n\nAug 9, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n\n\n如何使用 Python jupyter-book 建立一本書\n\n\n\n\n\n\nother\n\npython\n\n\n\n\n\n\n\n\n\nJul 25, 2025\n\n\n紙魚\n\n\n\n\n\n\n\n\n\n\n\n\n使用 Quarto 建立 Blog\n\n\n第一篇文章，來分享這個部落格是怎麼建立的\n\n\n\nother\n\nquarto\n\n\n\n\n\n\n\n\n\nJul 23, 2025\n\n\n紙魚\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/first-article/index.html",
    "href": "posts/first-article/index.html",
    "title": "使用 Quarto 建立 Blog",
    "section": "",
    "text": "很早以前就想建立自己的小小網站了，雖然在這之前，我用過 Blogger 寫文章，不過用得不是很順手，後來忘記帳密就沒再用了。到近期我才發現自己比較偏好用特定指令寫文章，這件事還是因為要寫數學筆記辦了 hackmd 才發現的。\n不得不說， hackmd 是一個非常好用的網站，不只可以用自己熟悉的 markdown 語法寫文章，也可以練習當時還不怎麼熟悉的 html 語法，同時跟一般的線上 markdown editor 相比，它既可以用 code 畫心智圖跟流程圖，也可以發佈成網站。一度想說就這樣繼續用下去吧，但它對我來說有個小小的缺點：寫的文章越長越容易卡頓。\n於是我開始異想天開：如果是自己建立的網站應該就不會卡了吧？\n在進入軟體業之前，我對網頁設計跟原理都沒有概念，進入軟體業之後雖然稍微有了一點”常識”，也接觸一些諸如 gitbook 等用來寫說明文件非常方便的軟體服務，但對於網頁是怎麼從寫成到上線，還是只有很模糊的：「呃…總之就是先在 localhost 寫一寫，再丟到測試機檢查，沒問題再丟到正式機吧？」過程中會用到的技術幾乎是0概念，但我還是很興奮地去研究各種可能的方案。\n第一個閃過的想法，是從頭學 html 跟 css 語法，自己刻一個網站，但我很快就發現非常花時間，而且要用其他引擎渲染 markdown 數學符號，實在是太麻煩。第二個想法是用 C# 建立網站，也是有同樣的問題，再加上 C# 的語法長得實在是看得不習慣(也可能是我只喜歡語法簡潔的東西，像是 markdown 或是 python，方案二也放棄了。\n第三個想法，就是用 python 或是 r 的相關套件來建立模板，有需要再自己改模板就好，不過上了研究所後會用來做筆記的檔案類型不只 .md 檔，還有 .ipynb、.rmd、.r等等，雖然很多都是 markdown 的延伸，但還是想要盡可能的在不改變副檔名的前提下整合他們。同時又想找美觀又可以調整 light/ dark theme 的模板來使用。就這樣多方考慮後我選擇了 Quarto 來作為我的模板，主要原因是官網上提供的範例無論是在提供的功能還是美觀方面看起來都非常吸引人！也支援前述提到的檔案格式，再加上官網上的教學看起來相當易懂，於是就來用用看了。想要看完整教學的可以的點此。"
  },
  {
    "objectID": "posts/first-article/index.html#在本機localthost檢視網頁",
    "href": "posts/first-article/index.html#在本機localthost檢視網頁",
    "title": "使用 Quarto 建立 Blog",
    "section": "在本機(localthost)檢視網頁",
    "text": "在本機(localthost)檢視網頁\n檢視網頁有2種方法:\n\n第一種：在 Terminal cd 到目前 Project 的資料夾，使用 quarto preview 指令。這會另外開啟常用瀏覽器檢視，指令碼複製如下：\n\nquarto preview\n\n第二種：在 Vscode 右上角有個  的符號，點擊可在右側 preview 網頁渲染結果。\n\n兩種方法都不錯，我覺得第一種方法適合螢幕小或想要檢視不同瀏覽器運作情況的人，第二種適合電腦螢幕大時使用，看個人需求了。\n知道怎麼檢視網頁後，接下來就可以認識 Blog Project 的架構跟調整設定了。"
  },
  {
    "objectID": "posts/first-article/index.html#首頁文章按日期最新排列",
    "href": "posts/first-article/index.html#首頁文章按日期最新排列",
    "title": "使用 Quarto 建立 Blog",
    "section": "首頁文章按日期最新排列",
    "text": "首頁文章按日期最新排列\n若想所有文章按日期最新排列，可以在 Project 下最外層的 _quarto.yml 調整，首先撰寫文章的 index.qmd 的YMAL都要設定日期，這部分預設模板有給：\ndate: \"2025-07-23\"\n　再來是修改最外層的_quarto.yml，新增下面語法\nlisting:\n  contents: posts\n  sort: \"date desc\"  # 日期最新的在前面\n需要注意 yaml 的順序跟階層關係很重要，順序跟階層不對會報錯。"
  },
  {
    "objectID": "posts/first-article/index.html#light-dark-theme-切換",
    "href": "posts/first-article/index.html#light-dark-theme-切換",
    "title": "使用 Quarto 建立 Blog",
    "section": "light / dark theme 切換",
    "text": "light / dark theme 切換\n一樣修改最外層的，語法如下：\nformat:\n  html:\n    theme:\n      light: flatly\n      dark: darkly\n這樣網站的右上角會出現一個小小的切換鈕，但個人覺得這個設計不太直觀，有機會再來研究看看可以怎麼改。"
  },
  {
    "objectID": "posts/first-article/index.html#插入目錄在每篇文章",
    "href": "posts/first-article/index.html#插入目錄在每篇文章",
    "title": "使用 Quarto 建立 Blog",
    "section": "插入目錄在每篇文章",
    "text": "插入目錄在每篇文章\n一樣在最外層的 _quarto.yaml 的 format:層下輸入\n    toc: true\n    toc-location: body\n    toc-depth: 2\n    toc-title: \"目錄\"\n    number-sections: false\n第一個語法會召喚開啟文章目錄，第二個則是目錄出現位置，body是文章開頭，另有left(文章左側)跟right(文章右側)可選。\n第三個是文章目錄在直接顯示時要顯示 header 幾，這裡的 2 表示在網頁剛載入時，目錄會顯示文章到 header 2 (markdown 語法 ## )為止的標題。\n\n注意如果前面的toc-location設定為left或right，用滑鼠點擊大 header 還是可以展開底下所有的小 header，只是初始載入會隱藏。\n\nnumber-sections則是要不要幫每個 header 標上編號，格式按 header 大小為 1、1.1、1.1.1…，以此類推，我覺得很醜所以用false取消編號。如果這個語法沒有設定，會導致有些檔案格式的文章如.qmd不編號，.md卻編號的情況，因此如果要統一還是要強制設定。"
  },
  {
    "objectID": "posts/first-article/index.html#轉換檔名",
    "href": "posts/first-article/index.html#轉換檔名",
    "title": "使用 Quarto 建立 Blog",
    "section": "轉換檔名",
    "text": "轉換檔名\n.qmd為 Quarto 官方提供的檔案格式，雖然用它寫 markdown + run python 很好用，但有時候要 render 時卻會出錯，找不出問題時有一個暴力硬解法－轉換副檔名為.ipynb。\nquarto convert your_file.qmd --to ipynb\n轉換後大致上可以無痛 work ，但有時有些設定會跑掉，還是要先 preview 檢查。"
  },
  {
    "objectID": "posts/first-article/index.html#footnotes",
    "href": "posts/first-article/index.html#footnotes",
    "title": "使用 Quarto 建立 Blog",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nrmd可以使用python，但其原理是要通過R的套件使用，但qmd則是可以直接用python處理。↩︎"
  },
  {
    "objectID": "posts/make-app/index.html",
    "href": "posts/make-app/index.html",
    "title": "使用python做離線倒數計時器",
    "section": "",
    "text": "這篇文章有點流水帳，就是一篇製作玩具的過程隨筆。用AI寫程式可以做到自己以前做不到的，但遇到問題還是要想辦法解決，解決問題還是需要思考跟經驗，所以我想還是紀錄一下，供日後參考囉。"
  },
  {
    "objectID": "posts/make-app/index.html#使用環境與套件",
    "href": "posts/make-app/index.html#使用環境與套件",
    "title": "使用python做離線倒數計時器",
    "section": "使用環境與套件",
    "text": "使用環境與套件\n使用環境\n\nWindows 11\npython version: 3.12.5\n\n使用套件:\n\ntkinter\n\n\n製作 GUI 的基本套件，優點是簡單，缺點是UI有些陽春\n\n\ncustomtkinte\n\n\nUI比較美觀的套件，用來優化舊有UI。\n\n\nplaysound\n\n\n播放聲音用的套件\n\n\npyinstaller\n\n\n製作exe的套件"
  },
  {
    "objectID": "posts/make-app/index.html#第一步開需求",
    "href": "posts/make-app/index.html#第一步開需求",
    "title": "使用python做離線倒數計時器",
    "section": "第一步：開需求",
    "text": "第一步：開需求\n我的需求如下：\n\n每30分鐘跳視窗提醒休息5分鐘，使用者按按鈕再繼續計時。\n螢幕上要顯示剩下幾分鐘。\n以秒為單位更新畫面。"
  },
  {
    "objectID": "posts/make-app/index.html#第二步丟ai生架構",
    "href": "posts/make-app/index.html#第二步丟ai生架構",
    "title": "使用python做離線倒數計時器",
    "section": "第二步：丟AI生架構",
    "text": "第二步：丟AI生架構\n把需求丟給AI後，生了一個架構出來\nimport tkinter as tk\nfrom tkinter import messagebox\nimport time\nimport threading\n\n# 時間設定（秒）\nWORK_DURATION = 30 * 60   # 30分鐘\nBREAK_DURATION = 5 * 60   # 5分鐘\n\n# GUI 主視窗\nroot = tk.Tk()\nroot.title(\"番茄鐘計時器\")\nroot.geometry(\"320x180\")\nroot.resizable(False, False)\n\nstatus_label = tk.Label(root, text=\"準備中...\", font=(\"Arial\", 16))\nstatus_label.pack(pady=10)\n\ntime_label = tk.Label(root, text=\"剩餘時間：00:00\", font=(\"Arial\", 32))\ntime_label.pack(pady=10)\n\n# 控制計時的旗標\nstop_flag = threading.Event()\n\ndef format_time(seconds):\n    minutes = seconds // 60\n    secs = seconds % 60\n    return f\"{minutes:02}:{secs:02}\"\n\ndef run_timer(duration, status_text, done_message):\n    remaining = duration\n\n    # 更新狀態文字\n    root.after(0, lambda: status_label.config(text=status_text))\n\n    while remaining &gt;= 0 and not stop_flag.is_set():\n        display = f\"剩餘時間：{format_time(remaining)}\"\n        root.after(0, lambda d=display: time_label.config(text=d))\n        time.sleep(1)\n        remaining -= 1\n\n    if not stop_flag.is_set():\n        root.after(0, lambda: messagebox.showinfo(\"提醒\", done_message))\n\ndef timer_loop():\n    while not stop_flag.is_set():\n        run_timer(WORK_DURATION, \"⏱ 工作中\", \"⏰ 工作時間結束！請休息 5 分鐘\")\n        run_timer(BREAK_DURATION, \"☕ 休息中\", \"✅ 休息結束，準備進入下一輪\")\n\ndef start_timer():\n    stop_flag.clear()\n    threading.Thread(target=timer_loop, daemon=True).start()\n\ndef stop_timer():\n    stop_flag.set()\n    status_label.config(text=\"計時已停止\")\n    time_label.config(text=\"剩餘時間：00:00\")\n\n# 按鈕 UI\nbtn_frame = tk.Frame(root)\nbtn_frame.pack(pady=5)\n\nstart_btn = tk.Button(btn_frame, text=\"開始計時\", command=start_timer, font=(\"Arial\", 12))\nstart_btn.pack(side=tk.LEFT, padx=10)\n\nstop_btn = tk.Button(btn_frame, text=\"結束計時\", command=stop_timer, font=(\"Arial\", 12))\nstop_btn.pack(side=tk.RIGHT, padx=10)\n\n# 啟動 GUI 主迴圈\nroot.mainloop()\n做出來的畫面像這樣：\n\n但用 tkinter 做出來的介面有點醜，於是改用customtkinte替代，再追加希望有聲音提醒的需求，於是有了第二版：\nimport customtkinter as ctk\nimport time\nimport threading\nfrom tkinter import messagebox\nfrom playsound import playsound\n\nWORK_DURATION = 30 * 60\nBREAK_DURATION = 5 * 60\nSOUND_FILE = \"ding.mp3\"\n\nctk.set_appearance_mode(\"dark\")  # 或 \"light\"\nctk.set_default_color_theme(\"blue\")\n\napp = ctk.CTk()\napp.title(\"番茄鐘計時器\")\napp.geometry(\"360x220\")\n\nstatus_label = ctk.CTkLabel(app, text=\"準備中...\", font=(\"Arial\", 18))\nstatus_label.pack(pady=10)\n\ntime_label = ctk.CTkLabel(app, text=\"剩餘時間：00:00\", font=(\"Arial\", 32))\ntime_label.pack(pady=10)\n\nstop_flag = threading.Event()\n\ndef format_time(seconds):\n    minutes = seconds // 60\n    secs = seconds % 60\n    return f\"{minutes:02}:{secs:02}\"\n\ndef run_timer(duration, status_text, done_message):\n    remaining = duration\n    status_label.configure(text=status_text)\n    while remaining &gt;= 0 and not stop_flag.is_set():\n        time_label.configure(text=f\"剩餘時間：{format_time(remaining)}\")\n        time.sleep(1)\n        remaining -= 1\n    if not stop_flag.is_set():\n        threading.Thread(target=lambda: playsound(SOUND_FILE), daemon=True).start()\n        messagebox.showinfo(\"提醒\", done_message)\n\ndef timer_loop():\n    while not stop_flag.is_set():\n        run_timer(WORK_DURATION, \"⏱ 工作中\", \"⏰ 工作時間結束！請休息 5 分鐘\")\n        run_timer(BREAK_DURATION, \"☕ 休息中\", \"✅ 休息結束，準備進入下一輪\")\n\ndef start_timer():\n    stop_flag.clear()\n    threading.Thread(target=timer_loop, daemon=True).start()\n\ndef stop_timer():\n    stop_flag.set()\n    status_label.configure(text=\"計時已停止\")\n    time_label.configure(text=\"剩餘時間：00:00\")\n\nbtn_frame = ctk.CTkFrame(app)\nbtn_frame.pack(pady=10)\n\nstart_btn = ctk.CTkButton(btn_frame, text=\"開始計時\", command=start_timer)\nstart_btn.pack(side=\"left\", padx=10)\n\nstop_btn = ctk.CTkButton(btn_frame, text=\"結束計時\", command=stop_timer)\nstop_btn.pack(side=\"right\", padx=10)\n\napp.mainloop()\n介面長得像這樣：　\n\n好看多了！\n其實不用聲音檔，光有這樣的架構，再寫個 bat 呼叫腳本其實就能用了，但到這裡我開始越來越貪心，想要弄得更精細，於是又加了2個需求\n\n聲音檔分成2個，工作時和休息時的音效不同\n聲音只播一次，且要跟訊息一起出現"
  },
  {
    "objectID": "posts/make-app/index.html#第三步微調程式與參數",
    "href": "posts/make-app/index.html#第三步微調程式與參數",
    "title": "使用python做離線倒數計時器",
    "section": "第三步：微調程式與參數",
    "text": "第三步：微調程式與參數\n\n聲音檔分成2個\n實際上需要改動2個地方，一個是在函數run_timer增加區分工作跟休息的音效，另一個是在函數timer_loop中塞入2個聲音檔。音檔可以自行去網路上找喜歡的，並且建議轉成.wav檔格式，執行程式時比較不會出問題(像.mp3就常會有有時可以順利播放有時無法)\n# 主循環：工作 → 休息 → 循環\ndef timer_loop():\n    while not stop_flag.is_set():\n        run_timer(WORK_DURATION, \"⏱ 工作中\", \"⏰ 工作結束！請休息 5 分鐘\", SOUND_FILE)\n        run_timer(BREAK_DURATION, \"☕ 休息中\", \"✅ 休息結束，準備進入下一輪\", SOUND_FILE2)\n\n\n聲音只播一次，且跟訊息一起出現\n這需要調整兩個函數：\n# 播放音效（非阻塞）\ndef play_sound(file):\n    try:\n        pygame.mixer.music.load(file)\n        pygame.mixer.music.play()\n    except Exception as e:\n        print(f\"⚠ 播放音效失敗：{e}\")\n\n# 執行計時器\n# 這裡使用非阻塞方式播放音效，避免阻塞主線\ndef run_timer(duration, status_text, done_message, sound_file):\n    remaining = duration\n    status_label.configure(text=status_text)\n\n    while remaining &gt;= 0 and not stop_flag.is_set():\n        time_label.configure(text=f\"剩餘時間：{format_time(remaining)}\")\n        time.sleep(1)\n        remaining -= 1\n\n    if not stop_flag.is_set():\n        play_sound(sound_file)  # ✅ 非阻塞播放音效\n        messagebox.showinfo(\"提醒\", done_message)  # ✅ 等待使用者按下「確定」\n\n\n自訂音效開啟/關閉\n這裡指的是自訂音效，window預設的視窗跳出音效不在此範圍。需要增加/修改的指令有：\nsound_enabled = ctk.BooleanVar(value=True)  # 預設開啟音效\n這條程式需要放在主視窗 UI 剛建立的時候，也就是app = ctk.CTk()之後，不然會報錯。\n其次是修改 play_sound()：\ndef play_sound(file):\n    if not sound_enabled.get():\n        return  # 如果沒勾選，就不播放音效\n    try:\n        pygame.mixer.music.load(file)\n        pygame.mixer.music.play()\n    except Exception as e:\n        print(f\"⚠ 播放音效失敗：{e}\")\n就可以得到一個勾選是否要啟用音效的欄位了。\n\n\n配合打包成exe的調整\n因為py檔在執行程式時會認附加檔案的路徑，即使打包成exe後也是如此，因此需要就這一段做微調。\nimport os\nimport sys\n\n# 取得正確路徑（支援 pyinstaller 打包後的執行檔）\ndef resource_path(relative_path):\n    \"\"\"取得資源真實路徑（支援開發階段與打包後）\"\"\"\n    try:\n        base_path = sys._MEIPASS  # PyInstaller 的暫存資料夾\n    except Exception:\n        base_path = os.path.abspath(\".\")\n    return os.path.join(base_path, relative_path)\n\n# 使用方式：\nsound_file_path = resource_path(\"sound.wav\")\n# 程式使用 resource_path()，就可以正確找到聲音檔了。\n\n# 例如播放聲音\nimport playsound\nplaysound.playsound(sound_file_path)\n執行時，PyInstaller 會自動把聲音檔解壓到臨時目錄中，這樣就可以找到聲音檔了。\n\n如果不使用resource_path()會怎麼樣？\n由於 PyInstaller 會把打包成一個 .exe。當執行這個 .exe 時，它會先解壓所有檔案到一個臨時目錄（通常是 %TEMP%_MEIxxxxx），然後才開始執行程式。如果沒有resource_path()就會導致找不到檔案，因為它找到臨時目錄去了。\n\n\n\n加入自定義圖示\n正常不做調整的情況下，視窗圖示為，但我想換掉變成自己的。先找一個 .png 轉成 .ico 圖示，放進同一個專案資料夾。接下來要做的事跟前面的音檔類似 :\n# 設定視窗圖示\nicon_path = resource_path(ICON_FILE)  # 使用之前定義的資源路徑函數\napp.iconbitmap(icon_path)  # 必須是 .ico 格式"
  },
  {
    "objectID": "posts/make-app/index.html#第四步打包成exe",
    "href": "posts/make-app/index.html#第四步打包成exe",
    "title": "使用python做離線倒數計時器",
    "section": "第四步：打包成exe",
    "text": "第四步：打包成exe\n用pyinstaller進行打包，首先要先安裝套件:\npip install pyinstaller\n\n基本指令\n打包的基本指令為\npyinstaller your_script.py\n執行完成後系統會提示放在 .\\dist的資料夾下，具體結構為：\nyour_script/\n├── dist/\n│   └── your_script.exe  ← 可執行檔在這裡\n├── build/\n├── your_script.spec \nbuild/ 和 .spec 是中間產物，可以保留也可以刪除。\n除此之外還有常用附加指令：\n\n\n\n\n\n\n\n參數\n說明\n\n\n\n\n--onefile\n打包成單一 .exe 檔案（預設會拆成很多檔）\n\n\n--noconsole\n不顯示命令列（適合正式 GUI 程式），不輸入時點擊exe會跳出cmd畫面。\n\n\n--icon=icon.ico\n指定執行檔圖示\n\n\n\n\n實作注意事項：\n\n--onefile建議必加，不然會跑出很多資料夾or檔案 有點像遊戲拆包\n--noconsole 在測試階段可以不用加入，方便檢查程式被打包成exe後會不會有前面沒有出現過的錯誤訊息。\n\n\n\n\n加入附加檔\n假設加入的聲音為sounds.wav，那麼指令為：\n--add-data \"sounds.wav;.\"\n這裡的;後面是資料夾的意思，.表示跟主程式一樣放在同一個資料夾。如果有兩個就在後面繼續使用此指令。\n如果聲音檔跟主程式放在不同資料夾，像這樣：\nproject/\n├── main.py\n└── sounds/\n    ├── click.wav\n    └── error.wav\n那指令就是：\npyinstaller --onefile --add-data \"sounds;sounds\" main.py\n代表「把 sounds/ 整個資料夾加到 .exe 所在目錄中」\n\n注意：\n如果有設定前面的圖示，一樣需要用 --add-data \"XXX.ico;.\"，不然它會找不到檔案。\n\n\n\n加入icon\n這裡指的是打包成 exe 時的圖示，指令為：\n--icon=icon.ico\n是顯示exe程式的圖示，可以自己找或加工一張png，再去轉成ico來用。生成exe後圖示不一定馬上會出現，通常過一段時間才會出現。"
  },
  {
    "objectID": "posts/make-app/index.html#打包過程遇到的困難",
    "href": "posts/make-app/index.html#打包過程遇到的困難",
    "title": "使用python做離線倒數計時器",
    "section": "打包過程遇到的困難",
    "text": "打包過程遇到的困難\n在測試py腳本時一切順利，不過在打包exe遇到套件沒有安裝的神奇狀況，而且問AI，是它給的做法都完全沒用，後來仔細觀察pyinstaller產出的log才發現原來是我平常都把套件都安裝在 venv 的虛擬環境下，但是 pyinstaller 在執行時沒有調整過就會自動找全域環境，於是就用指令啟動虛擬環境，確認虛擬環境下有安裝pyinstaller後再執行打包就沒問題了。\n中間還遇到一個有點蠢的問題XD，我常用的虛擬環境安裝在 “桌面” 下的資料夾，好死不死路徑名稱是中文的，導致專案在Vscode自動指定虛擬環境後還遇到因為無法辨識中文路徑而舞法啟用python的狀況XD。其實只要再建一個虛擬環境在C槽就好，但我就是不死心對原本的虛擬環境有感情ㄌ，一直找其他方法，後來用指令啟動虛擬環境後就好了，白繞了一點路XD。\n不過最後我還是乖乖建新的虛擬環境了，不然其他專案早晚會出問題"
  },
  {
    "objectID": "posts/pytorch2/pytorch2.html",
    "href": "posts/pytorch2/pytorch2.html",
    "title": "重新認識pytorch(2)",
    "section": "",
    "text": "RNN，全名為循環神經網路(Recurrent Neural Network)，是具有記憶功能的模型。它可以發現樣本彼此之間的相互關係，適合處理 series data 的特徵 ，可應用於處理文字資料分類及time series等。\nRNN 的主要限制有：\n現今更常用的是 Transformer 模型，但 RNN 在資源有限或學習原理時仍很有價值。本次暫時不使用 pytorch 套件，除了簡單介紹 RNN 外，也會藉由實作手刻一個簡單的 RNN。"
  },
  {
    "objectID": "posts/pytorch2/pytorch2.html#模型定義",
    "href": "posts/pytorch2/pytorch2.html#模型定義",
    "title": "重新認識pytorch(2)",
    "section": "模型定義",
    "text": "模型定義\n因為是手刻，所以激勵函數(activation function)及其導函數需自行指定，這裡用的 \\(\\sigma (.)\\) 是\n\\[\\frac{1}{1+e^{-x}}\\]\n其導數為：\n\\[\\frac{e^{-x}}{1+e^{-x}}=\\frac{1}{1+e^{-x}}(1-\\frac{1}{1+e^{-x}})\\]\n\nimport copy, numpy as np\n\n# 忽略所有數值運算警告（如 overflow, invalid value 等）\nnp.seterr(over='ignore', invalid='ignore')\n\n\n# activation function\ndef sigmoid(x):\n    output = 1/(1+np.exp(-x))\n    return output\n\n# derivative of active function\ndef sigmoid_output_to_deriv(output):\n    return output*(1-output)\n\n\n定義模型參數\n再來在建立模型前，先定義模型參數，這裡我們將隱藏層的權重設為synapse_0(輸入及輸出符合 hidden dimension)；輸出層的權重設為synapse_1。\n\nlr = 0.1\ninput_dim = 2 # (a, b)\nhidden_dim = 16\nout_dim = 1 # c\n\n\nsynapse_0 = (2*np.random.random((input_dim,hidden_dim))-1)*0.05\nsynapse_1 = (2*np.random.random((hidden_dim,out_dim))-1)*0.05\nsynapse_h = (2*np.random.random((hidden_dim,hidden_dim))-1)*0.05\n\n# 反向傳遞的權重更新(平時寫在最佳化器裡)\nsynapse_0_up = np.zeros_like(synapse_0)\nsynapse_1_up = np.zeros_like(synapse_1)\nsynapse_h_up = np.zeros_like(synapse_h)\n\n然後每次執行模型前應初始化模型，首次執行時 output 應為 0，總誤差應為 0。\n# 預測值\nd = np.zeros_like(c)\noverallError = 0\n\n# 反向傳遞的誤差紀錄\nlayer_2_deltas = []\nlayer_1_values = []\n\nlayer_1_values.append(np.ones(hidden_dim)*0.1) \n# 因為一開始沒有 hidden layer 初值設為0.1"
  },
  {
    "objectID": "posts/pytorch2/pytorch2.html#執行模型正向",
    "href": "posts/pytorch2/pytorch2.html#執行模型正向",
    "title": "重新認識pytorch(2)",
    "section": "執行模型：正向",
    "text": "執行模型：正向\n實際執行模型時，會讓資料先做正向 (方向是起點到終點)，然後再做反向更新權重(方向為終點回到起點)。\n\n任務說明（概念）\n我們的目標是： 對兩個二進位數 \\(a\\)、\\(b\\)，每一個位元進行減法 \\(c = a - b\\) 的預測。 這裡的模型是一個簡單的 RNN，用來逐位（bit-by-bit）預測輸出 \\(c\\) 的每一位元 \\(c_t\\)，其中 \\(t\\) 表示時間步，從最低位（右邊）往左處理。\n\n\n符號定義\n\n\n\n\n\n\n\n\n數學符號\n意義\n維度\n\n\n\n\n\\(x_t\\)\n時間步 \\(t\\) 的輸入向量\n\\(\\mathbb{R}^2\\)\n\n\n\\(y_t\\)\n正確輸出值（目標）\n\\(\\mathbb{R}\\)\n\n\n\\(\\hat{y}_t\\)\n模型在時間步 \\(t\\) 的預測\n\\(\\mathbb{R}\\)\n\n\n\\(h_t\\)\n隱藏層狀態\n\\(\\mathbb{R}^h\\)\n\n\n\\(W_{xh}\\)\n輸入到隱藏層的權重矩陣\n\\(\\mathbb{R}^{2 \\times h}\\)\n\n\n\\(W_{hh}\\)\n前一個隱藏狀態到現在的隱藏狀態\n\\(\\mathbb{R}^{h \\times h}\\)\n\n\n\\(W_{hy}\\)\n隱藏層到輸出層的權重\n\\(\\mathbb{R}^{h \\times 1}\\)\n\n\n\\(\\sigma(\\cdot)\\)\nsigmoid 函數：\\(\\sigma(x) = \\frac{1}{1 + e^{-x}}\\)\n\n\n\n\\(e_t\\)\n預測誤差：\\(y_t - \\hat{y}_t\\)\n\\(\\mathbb{R}\\)\n\n\n\\(\\delta^{(2)}_t\\)\n輸出層誤差對應的 delta\n\\(\\mathbb{R}\\)\n\n\n\n整體流程為：對於每個位元時間步 \\(t\\)，模型進行以下計算：\n\\[\n\\begin{aligned}\nx_t &= \\begin{bmatrix} a_t \\\\ b_t \\end{bmatrix} \\\\\nh_t &= \\sigma(x_t W_{xh}) + h_{t-1} W_{hh} \\\\\n\\hat{y}_t &= \\sigma(h_t W_{hy}) \\\\\ne_t &= y_t - \\hat{y}_t \\\\\n\\delta^{(2)}_t &= e_t \\cdot \\hat{y}_t (1 - \\hat{y}_t)\n\\end{aligned}\n\\]\n其中 \\(h_0 = \\vec{0}\\) 初始為零向量。\n步驟：\n\n輸入（每一位 bit）\n\n給定時間步 \\(t\\) 的輸入 bit：\n\\[\nx_t = \\begin{bmatrix} a_t \\\\ b_t \\end{bmatrix} \\in \\mathbb{R}^2\n\\]\n\n隱藏層計算\n\n（此模型使用的是「非標準」RNN 形式，即先對輸入做 sigmoid，再加上前一個 hidden state）\n\\[\nh_t = \\sigma(x_t W_{xh}) + h_{t-1} W_{hh}\n\\]\n其中：\n\n\\(h_{t-1}\\) 是上一時間步的隱藏層狀態\n若要用「標準」RNN 形式應為：\n\\[\nh_t = \\sigma(x_t W_{xh} + h_{t-1} W_{hh})\n\\]\n\n\n輸出層計算\n\n將隱藏狀態傳到輸出層並經過 sigmoid：\n\\[\n\\hat{y}_t = \\sigma(h_t W_{hy})\n\\]\n\n預測誤差\n\n目標輸出為 \\(y_t\\)，模型預測為 \\(\\hat{y}_t\\)，則誤差為：\n\\[\ne_t = y_t - \\hat{y}_t\n\\]\n\n\n輸出層的反向傳播（誤差梯度）\n使用平方誤差損失函數，其對預測輸出 \\(\\hat{y}_t\\) 的導數為：\n\\[\n\\frac{\\partial L_t}{\\partial \\hat{y}_t} = -(y_t - \\hat{y}_t) = -e_t\n\\]\n但由於輸出層有經過 sigmoid，需乘上 sigmoid 的導數：\n\\[\n\\sigma'(\\hat{y}_t) = \\hat{y}_t (1 - \\hat{y}_t)\n\\]\n因此輸出層 delta 為：\n\\[\n\\delta^{(2)}_t = e_t \\cdot \\hat{y}_t (1 - \\hat{y}_t)\n\\]\n\n\n預測結果記錄（量化輸出）\n模型最終預測結果會被四捨五入為 0 或 1：\n\\[\n\\hat{c}_t = \\text{round}(\\hat{y}_t)\n\\]\n\n\n整體誤差統計\n若將每一位的絕對誤差做加總，可以得到一整筆資料的總預測誤差：\n\\[\n\\text{OverallError} = \\sum_{t=1}^{T} |e_t|\n\\]\n\n\ncode\n開始執行，先做正向：\n\ndef RNN_positive(a, b, c):\n    # 定義模型參數 (前面已做過)\n    d = np.zeros_like(c)\n    overallError = 0\n    layer_1_values = [np.zeros((1, hidden_dim))]\n    layer_2_deltas = []\n\n    for position in range(binary_dim):\n        # input genarate and output genarate\n        X = np.array([[a[binary_dim - position - 1], b[binary_dim - position - 1]]])\n        # X = X.reshape(1, 2)  # 明確定義為 2D（1 row, 2 columns）\n        # 正解\n        y = np.array([[c[binary_dim - position - 1]]]).T \n        # (input + hidden) -&gt; new hidden\n        layer_1 = sigmoid(np.dot(X,synapse_0)) + np.dot(layer_1_values[-1],synapse_h) # 出來 1 x hidden_dim 需轉置\n        layer_2 = sigmoid(np.dot(layer_1, synapse_1))\n        # hidden*( matrix of hidden to output) -&gt; output\n\n        layer_2_error = y - layer_2\n        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_deriv(layer_2))\n        overallError += np.abs(layer_2_error[0])\n\n        d[binary_dim - position - 1] = np.round(layer_2[0][0])\n        layer_1_values.append(copy.deepcopy(layer_1))\n        future_layer_1_delta = np.zeros(hidden_dim)\n    return d, layer_1_values, layer_2_deltas, overallError\n\n\n\n\n\n\n\ncode 逐列解說\n\n\n\n\n\n每一個迴圈步驟代表處理一個位元（從最低位開始）。\nfor position in range(binary_dim):\n\n這是循環處理每一個二進位的位元（從第 0 位到第 binary_dim - 1 位）。\n通常是從右到左（最低位到最高位）。\n\nX = np.array([a[binary_dim - position - 1], b[binary_dim - position - 1]])\n\n取出第 position 位的兩個輸入 bit：a 和 b。\n二進位是從右往左計算的，所以要用 binary_dim - position - 1 來取得正確位元。\n\ny = np.array([c[binary_dim - position - 1]]).T\n\ny 是正確答案 c 的當前位元。\n.T 是把它轉置成列向量，以配合後續矩陣運算。\n\nlayer_1 = sigmoid(np.dot(X, synapse_0)) + np.dot(layer_2_values[-1], synapse_h)\n\n這是計算目前時間步的隱藏層輸出。\n第一部分：X @ synapse_0 是輸入層乘上輸入到隱藏層的權重。\n第二部分：layer_2_values[-1] @ synapse_h 是上一時間步的隱藏狀態與 recurrent 權重相乘。\n加總後通過 sigmoid 激勵函數，得到目前時間步的隱藏層狀態。\n\nlayer_2 = sigmoid(np.dot(layer_1, synapse_1))\n\n將隱藏層輸出通過輸出層權重 synapse_1，並套用 sigmoid，得到預測結果（0 或 1 的機率）。\n\nlayer_2_error = y - layer_2\nlayer_2_deltas.append(layer_2_error * sigmoid_output_to_deriv(layer_2))\n\n計算這一位的預測誤差。\n將誤差乘以 sigmoid 導數，得到反向傳播時的 delta（誤差梯度）。\n把 delta 儲存起來，稍後會用來做權重更新。\n\noverallError += np.abs(layer_2_error[0])\n\n累加這一位的絕對誤差，用來觀察整體模型在這一筆資料上的表現。\n\nd[binary_dim - position - 1] = np.round(layer_2[0][0])\n\n根據預測值進行四捨五入（0 或 1），儲存為預測結果的其中一位。\nd 最終會是整筆輸出結果的二進位數。\n\nlayer_1_values.append(copy.deepcopy(layer_1))\n是用來把當前時間步的 隱藏層輸出 (layer_1) 儲存起來，以便在未來的 反向傳播（Backpropagation Through Time, BPTT） 中使用。\n\n使用 deepcopy() 可以確保每個時間步的隱藏層輸出都正確保留下來，不被未來時間步覆蓋或污染\n把每個時間步的 layer_1 加到 layer_1_values 這個 list 裡面\n這個 list 最後會長成：\nlayer_1_values = [h_{-1}, h_0, h_1, ..., h_{T-1}]\n\nfuture_layer_1_deltas = np.zeros(hidden_dim)\n\n為了做後續反向之用，清空 future_layer_1_deltas。\n\n\n\n\n再做反向的權重更新："
  },
  {
    "objectID": "posts/pytorch2/pytorch2.html#執行模型反向",
    "href": "posts/pytorch2/pytorch2.html#執行模型反向",
    "title": "重新認識pytorch(2)",
    "section": "執行模型：反向",
    "text": "執行模型：反向\n這裡因為 RNN 的特性，反向時會加入 BPTT 演算法處理。理論部分在此略過，直接說明流程，整體流程為：\n給定時間步 \\(t = T-1, T-2, \\dots, 0\\)，反向傳播的數學表達為：\n\n計算隱藏層 delta\n\n\\[\n\\delta_t^{(1)} = \\delta_{t+1}^{(1)} W_{hh}^T + \\delta_t^{(2)} W_{hy}^T\n\\]\n\n累加權重梯度\n\n\\[\n\\Delta W_{hy} += h_t^T \\delta_t^{(2)}\n\\]\n\\[\n\\Delta W_{hh} += h_{t-1}^T \\delta_t^{(1)}\n\\]\n\n權重更新（一次更新）\n\n\\[\nW_{hy} \\leftarrow W_{hy} + \\eta \\cdot \\Delta W_{hy}\n\\]\n\\[\nW_{hh} \\leftarrow W_{hh} + \\eta \\cdot \\Delta W_{hh}\n\\]\n\n符號定義\n\n\n\n\n\n\n\n\n程式變數\n數學符號\n意義\n\n\n\n\nx_t\n\\(x_t \\in \\mathbb{R}^2\\)\n第 \\(t\\) 個時間步的輸入（兩個位元）\n\n\nh_t\n\\(h_t \\in \\mathbb{R}^h\\)\n第 \\(t\\) 個時間步的隱藏層輸出\n\n\n\\delta_t^{(2)}\n\\(\\delta_t^{(2)} \\in \\mathbb{R}\\)\n第 \\(t\\) 步的輸出層 delta（來自前向誤差）\n\n\n\\delta_t^{(1)}\n\\(\\delta_t^{(1)} \\in \\mathbb{R}^h\\)\n第 \\(t\\) 步的隱藏層 delta\n\n\nW_{hy}\n\\(\\text{synapse\\_1} \\in \\mathbb{R}^{h \\times 1}\\)\n隱藏層 → 輸出層的權重\n\n\nW_{hh}\n\\(\\text{synapse\\_h} \\in \\mathbb{R}^{h \\times h}\\)\n隱藏層（上一步）→ 隱藏層\n\n\nlr\n\\(\\eta\\)\n學習率\n\n\n\n\n\n數學推導\n\n隱藏層 delta 的計算\n\n根據鏈式法則，隱藏層的 delta 可由兩個部分反向傳遞而來：\n\n來自輸出層的誤差反傳：\n\\[\n\\delta_t^{(2)} W_{hy}^T\n\\]\n來自下一個時間步隱藏層的誤差反傳（RNN 的時間依賴）：\n\\[\n\\delta_{t+1}^{(1)} W_{hh}^T\n\\]\n\n因此總合為：\n\\[\n\\delta_t^{(1)} = \\delta_{t+1}^{(1)} W_{hh}^T + \\delta_t^{(2)} W_{hy}^T\n\\]\n其中 \\(\\delta_{t+1}^{(1)}\\) 是 未來時間的隱藏層 delta，一開始設為 0，然後逐步向後遞推。\n\n權重的梯度累積\n\n這部分對應於：\n\n輸出層權重更新項\n\n\\[\n\\Delta W_{hy} += h_t^T \\delta_t^{(2)}\n\\]\n（隱藏層 → 輸出層）\n\nRNN recurrent 權重更新項\n\n\\[\n\\Delta W_{hh} += h_{t-1}^T \\delta_t^{(1)}\n\\]\n（前一個隱藏層 → 當前隱藏層）\n\n權重更新\n\n在完成所有時間步的誤差累積之後，對所有權重進行梯度下降：\n\\[\nW_{hy} \\leftarrow W_{hy} + \\eta \\cdot \\Delta W_{hy}\n\\]\n\\[\nW_{hh} \\leftarrow W_{hh} + \\eta \\cdot \\Delta W_{hh}\n\\]\n\n\n\ncode\n\ndef RNN_negative(layer_1_values, layer_2_deltas, a, b):\n    global synapse_0, synapse_1, synapse_h\n    global synapse_0_up, synapse_1_up, synapse_h_up\n\n    future_layer_1_delta = np.zeros((1, hidden_dim))\n\n    for position in range(binary_dim):\n        X = np.array([[a[position], b[position]]])\n        layer_1 = layer_1_values[-position - 1]\n        prev_layer_1 = layer_1_values[-position - 2]\n        layer_2_delta = layer_2_deltas[-position - 1]\n\n        layer_1_delta = (\n            future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)\n        ) * sigmoid_output_to_deriv(layer_1)\n\n        synapse_1_up += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n        synapse_h_up += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n\n        synapse_0_up += X.T.dot(layer_1_delta)\n\n        future_layer_1_delta = layer_1_delta\n\n    # 更新權重\n    synapse_0 += synapse_0_up * lr\n    synapse_1 += synapse_1_up * lr\n    synapse_h += synapse_h_up * lr\n\n    # 清空更新梯度\n    synapse_0_up *= 0\n    synapse_1_up *= 0\n    synapse_h_up *= 0\n\n\n\n\n\n\n\ncode 逐列解說\n\n\n\n\n\nfor position in range(binary_dim):\n\n作用：從第一個 bit（position=0）開始，依序向後處理所有位元（bit）的位置，做反向傳播（從最後一個時間步往前）。\n\nX = np.array([a[position], b[position]])\n\n作用：取得第 position 位元的輸入，這裡是數字 a 和 b 在該位元的二進位值，組成一個長度為2的輸入向量 \\(x_t\\)。\n\nlayer_1 = layer_2_values[-position-1]  # 目前時間的hidden layer\n\n作用：取得對應時間點的隱藏層狀態 \\(h_t\\)。\n注意：layer_2_values 是時間序列的隱藏層列表，-position-1 從最後一個時間步往前索引。\n\nprev_layer_1 = layer_2_values[-position-2]  # 前時間的hidden layer\n\n作用：取得前一時間步（\\(t-1\\)）的隱藏層狀態 \\(h_{t-1}\\)，用於更新循環權重。\n\nlayer_2_deltas = layer_2_deltas[-position-1]\n\n作用：取得當前時間步輸出層的 delta \\(\\delta_t^{(2)}\\)，也就是輸出層的誤差梯度。\n\nlayer_1_deltas = (future_layer_1_deltas.dot(synapse_h.T) + layer_2_deltas.dot(synapse_1.T))\n\n作用：計算隱藏層的 delta \\(\\delta_t^{(1)}\\)，包含：\n\n\\(\\delta_{t+1}^{(1)}\\) 經由循環權重 \\(W_{hh}\\) 反向傳播的誤差 (future_layer_1_deltas.dot(synapse_h.T))\n\\(\\delta_t^{(2)}\\) 經由輸出層權重 \\(W_{hy}\\) 反向傳播的誤差 (layer_2_deltas.dot(synapse_1.T)) 這是 RNN 時間與層間反向誤差的加總。\n\n\nsynapse_1_up += np.atleast_2d(layer_1).T.dot(layer_2_deltas)\n\n作用：累加輸出層權重 \\(W_{hy}\\) 的梯度： \\(\\Delta W_{hy} += h_t^T \\delta_t^{(2)}\\) 這是根據誤差對權重的偏微分。\n\nsynapse_h_up += np.atleast_2d(prev_layer_1).T.dot(layer_1_deltas)\n\n作用：累加循環權重 \\(W_{hh}\\) 的梯度： \\(\\Delta W_{hh} += h_{t-1}^T \\delta_t^{(1)}\\) 用前一時間的隱藏狀態乘上當前時間的隱藏層 delta。\n\nfuture_layer_1_deltas = layer_1_deltas\n\n作用：將當前時間步的隱藏層 delta 儲存起來，作為下一個時間步（往前一位）計算的「未來隱藏層 delta」使用。\n這是反向傳播的關鍵：誤差從後面時間步向前傳遞。\n\n# 更新權重\nsynapse_0 += synapse_0_up * lr\nsynapse_1 += synapse_1_up * lr\n\n作用：使用累積的梯度 \\(\\Delta W\\) 按照學習率 \\(\\eta\\) 更新權重。 這幾行程式碼的作用是完成 反向傳播與權重更新後的梯度清零（reset），以下是每一行的說明（包含對應的數學概念）：\n\nsynapse_h += synapse_h_up * lr\n意義：\n\n將 recurrent 權重 \\(W_{hh}\\) 依照學習率 \\(\\eta\\) 更新：\n\n\\[\nW_{hh} \\leftarrow W_{hh} + \\eta \\cdot \\Delta W_{hh}\n\\]\n\n其中 synapse_h_up 是之前累積的權重梯度 \\(\\Delta W_{hh}\\)，學習率為 lr。\n\nsynapse_0_up *= 0\nsynapse_1_up *= 0\nsynapse_h_up *= 0\n意義：\n\n將所有已經使用過的梯度變數清零，為下一筆資料的訓練準備。\n對應數學上是將累積的梯度矩陣歸零：\n\n\\[\n\\Delta W_{xh} = 0, \\quad \\Delta W_{hy} = 0, \\quad \\Delta W_{hh} = 0\n\\]\n這麼做是因為每次訓練新一筆資料（或 batch）時，需要重新計算對應的權重梯度，避免與前一筆混在一起。"
  },
  {
    "objectID": "posts/pytorch2/pytorch2.html#結果",
    "href": "posts/pytorch2/pytorch2.html#結果",
    "title": "重新認識pytorch(2)",
    "section": "結果",
    "text": "結果\n\ndef binary2int(binary_array):\n    \"\"\"將二進位 ndarray 轉換為十進位整數\"\"\"\n    return int(\"\".join(str(int(b)) for b in binary_array), 2)\n\nError_list = []\nfor j, (a, b, c) in enumerate(data):\n    a_int = binary2int(a)\n    b_int = binary2int(b)\n    c_int = binary2int(c)\n    # print(f\"{a_int} + {b_int} = {c_int}\")\n\n    d, layer_1_values, layer_2_deltas, overallError = RNN_positive(a, b, c)\n  \n    RNN_negative(layer_1_values, layer_2_deltas, a, b)\n    if j % 100 == 0:\n      Error_list.append(overallError)\n\n\n    if j % 1000 == 0:\n        print(f\"Total error: {overallError}\")\n        print(f\"Prediction value: {d}\")\n        print(f\"True value: {c}\")\n        out = 0\n        for index, x in enumerate(reversed(d)):\n            out += int(x) * pow(2, index)\n        print(f\"{a_int} - {b_int} = {out}\")\n        print(\"----------\")\n\nTotal error: [3.97936582]\nPrediction value: [0 0 0 0 0 0 0 0]\nTrue value: [0 0 0 0 1 0 0 0]\n40 - 32 = 0\n----------\nTotal error: [3.24030251]\nPrediction value: [0 0 0 0 0 0 0 0]\nTrue value: [0 0 0 1 0 0 0 0]\n34 - 18 = 0\n----------\nTotal error: [3.93281865]\nPrediction value: [0 0 0 0 0 0 0 0]\nTrue value: [0 0 1 0 1 0 1 1]\n107 - 64 = 0\n----------\nTotal error: [3.99430241]\nPrediction value: [0 0 0 0 0 0 0 1]\nTrue value: [0 0 1 1 1 0 1 0]\n111 - 53 = 1\n----------\nTotal error: [3.87219041]\nPrediction value: [0 1 1 0 1 1 1 1]\nTrue value: [0 1 0 0 1 1 0 1]\n119 - 42 = 111\n----------\nTotal error: [3.14270565]\nPrediction value: [0 0 0 0 0 0 0 0]\nTrue value: [0 0 0 0 1 1 1 0]\n60 - 46 = 0\n----------\nTotal error: [3.16076726]\nPrediction value: [0 0 0 0 0 0 0 0]\nTrue value: [0 0 1 0 1 0 1 1]\n239 - 196 = 0\n----------\nTotal error: [2.5766328]\nPrediction value: [0 0 0 0 0 0 1 0]\nTrue value: [0 0 1 0 0 1 1 1]\n133 - 94 = 2\n----------\nTotal error: [2.59768901]\nPrediction value: [0 0 0 0 0 0 0 0]\nTrue value: [1 0 0 1 0 0 0 1]\n223 - 78 = 0\n----------\nTotal error: [3.55110057]\nPrediction value: [0 0 0 0 1 0 0 0]\nTrue value: [1 0 0 1 1 1 1 1]\n167 - 8 = 8\n----------\n\n\n從以上結果摘錄中可以看到，雖然因為都是手刻，有些資料在經過 acivative funciton 時發生溢位，倒致 Prediction value 變成 0 向量，但整體還算能動。把誤差化成圖：\n\nimport matplotlib.pyplot as plt\n# x 軸：資料點編號（第幾次）\nx = list(range(0,len(Error_list)*100, 100))\n# y 軸：每個值\ny = Error_list\n# 畫圖\nplt.plot(x, y)  # 折線圖 + 每點畫圈\nplt.xlabel(\"Step\")\nplt.ylabel(\"Value\")\nplt.title(\"Value over Time\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n可以發現有隨著資料量增加訓練越來越好的趨勢。"
  },
  {
    "objectID": "posts/pytorch2/pytorch2.html#文字資料應用原理",
    "href": "posts/pytorch2/pytorch2.html#文字資料應用原理",
    "title": "重新認識pytorch(2)",
    "section": "文字資料應用原理",
    "text": "文字資料應用原理\n文字是一種有順序的資料（句子 = 單字序列），例如：\n\n“I love time series.”\n\n每個字對整體句子的意思都有影響。RNN 透過「記憶」前面的資訊，來理解目前的輸入。\n以模型結構來說，\\(\\{x_t\\}\\)便是正確的文字序列資料(ex. “I love time series.”)\nRNN 處理文字資料的基本流程：\n\n文字預處理\n\n將句子分詞（tokenization）\n轉成數字（word to index）\n建立詞嵌入（embedding）\n\n建構 RNN 模型\n\n輸入層：嵌入向量\n隱藏層：RNN / LSTM / GRU\n輸出層：看任務類型（分類、預測下一字、標註）\n\n模型訓練與推論\n\n使用標準的損失函數（如交叉熵）\n訓練完模型後就能進行文字生成、分類或翻譯等任務\n\n\n應用場景舉例：\n\n\n\n\n\n\n\n任務\nRNN 的應用方式\n\n\n\n\n文字分類\n輸入整個句子，最後用 RNN 最後一個 hidden state 做分類（如情感分析）\n\n\n語言模型 / 文字生成\n給定前面幾個字，RNN 預測下一個字（或詞）\n\n\n機器翻譯\n使用 Encoder-Decoder 架構（雙 RNN），前半編碼原始語句，後半生成翻譯\n\n\n命名實體識別（NER）\n每個字都產出一個預測，使用 bidirectional RNN 處理前後文"
  },
  {
    "objectID": "posts/side-project1/side-project1.html",
    "href": "posts/side-project1/side-project1.html",
    "title": "Side Project - 簡易預估搭乘新竹客運假日從新竹到台中的時間",
    "section": "",
    "text": "這個 Side Project 的發想完全來自我個人生活中的需求。\n以前在大學時認識了一些台中人，或是畢業後留在台中工作的人，加上在在大學生活期間我愛上在台中的生活，畢業後即使在台北工作，有空時我還是會跟朋友約一約，前一天回到新竹，隔天搭乘新竹客運跟著新竹的朋友一起跑到朝馬去找老朋友吃飯、聊天、唱歌。不過這種難得的假日聚會，住在台中的朋友總是會事先負責訂位，確保我們都有店可去。而我們呢，則是負責不要遲到XD\n通常為了避免遲到，我跟朋友通常會搭早一點的客運出發。長久搭下來，主要影響客運的因素為會不會在路上塞車，經驗上來說，到台中時都會塞一小段。自從知道交通部有國道車流的開放資料後，我就想嘗試看看用國道的資料建模，看看能不能用神奇的 “占卜” ，讓我們成為時間精算師，再也不要搭這麼早的客運了！XD"
  },
  {
    "objectID": "posts/side-project1/side-project1.html#資料來源簡介",
    "href": "posts/side-project1/side-project1.html#資料來源簡介",
    "title": "Side Project - 簡易預估搭乘新竹客運假日從新竹到台中的時間",
    "section": "資料來源簡介",
    "text": "資料來源簡介\n使用來源為交通度高公局交通資料庫的開放資料，網址。\n我使用的欄位有：\n\nSectionID\nTravel_Speed\n\n以及在檔名擷取時間。\n我的訓練資料為 2024 年屬於國定假日範圍的資料，其中有 10 % 的資料屬於訓練階段的 valid set ， 其餘 90% 為 training set；用來測試模型的 test set 為 2025年上半年國定假日範圍的資料，期間為 1/1 ~ 8/30 。"
  },
  {
    "objectID": "posts/side-project1/side-project1.html#清資料",
    "href": "posts/side-project1/side-project1.html#清資料",
    "title": "Side Project - 簡易預估搭乘新竹客運假日從新竹到台中的時間",
    "section": "清資料",
    "text": "清資料\n主要流程為：\n\n將資料按2024年國定假日、符合新竹-台中的 Section 按 SectionID 爬下來\n補齊遺失值，基本使用 Cubic Spline 補齊遺失值，如果補出來的資料太不合理，例如嚴重超過速限，則考慮那一天的資料都移除。所幸只有228那天有問題，只移除這一天。\n最後用敘事性統計觀察資料有無異常。"
  },
  {
    "objectID": "posts/side-project1/side-project1.html#訓練資料",
    "href": "posts/side-project1/side-project1.html#訓練資料",
    "title": "Side Project - 簡易預估搭乘新竹客運假日從新竹到台中的時間",
    "section": "訓練資料",
    "text": "訓練資料\n流程：\n\n區分 training set, valid set，test set 為2025上半年的資料。\n訓練模型\n計算valid set RMSE、畫圖觀察\n確認OK後，拿 test set 試試\n計算test set RMSE、畫圖觀察\n\n確認都可以後再依 section 產出預測資料。\n\n指定 LSTM 的原因\n因為我想玩還有我很懶，原先在指定 LSTM 之前，有先考慮過使用 ARIMA 或是 SARIMA 模型來進行預測，不過指定這種經典的統計模型的缺點是滿吃對資料的觀察能力，我太菜了，沒有人在旁邊指導我撞牆可能會撞很久。此外，一直以來有耳聞過 LSTM 的用於 series data 的強大，也有看過一些與其他模型的預測能力比較的論文，像是這篇。\n神經網路家族的模型雖然複雜，但沒有特殊的統計假設；而且 LSTM 模型適合預測沒有突發事件影響的資料，我的資料搜查範圍僅限假日，基本上沒有突發事件影響。因此考慮後決定用 LSTM 模型來進行預測。\n\n\n模型架構\n試了好幾個參數後，得出的最好的模型架構與效果為\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size=4, hidden_layer_size=16, output_size=1, num_layers=1):\n        super().__init__()\n        self.hidden_layer_size = hidden_layer_size\n        self.num_layers = num_layers\n\n        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, batch_first=True)\n        self.linear = nn.Linear(hidden_layer_size, output_size)\n\n    def forward(self, input_seq):\n        batch_size = input_seq.size(0)\n        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_layer_size).to(input_seq.device)\n        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_layer_size).to(input_seq.device)\n\n        lstm_out, _ = self.lstm(input_seq, (h0, c0))\n        out = self.linear(lstm_out[:, -1, :])\n        return out\n\n\n模型參數設定\n基本參數為\n# 訓練參數\nseq_length = 15\npredict_step = 15 #一次預測15分鐘\nepochs = 30\npatience = 5 # early stop\n# Early stopping at epoch 12.\n最終設定的 LSTM 模型指定參數為\nLSTMModel(\n  (lstm): LSTM(4, 16, batch_first=True)\n  (linear): Linear(in_features=16, out_features=1, bias=True)\n)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = LSTMModel().to(device)\nloss_function = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n\n相關訓練數據\nRMSE 部分：\n\n\n\nset\nRMSE\n\n\n\n\nvalid set\n3.0401\n\n\ntest set\n6.0785\n\n\n\n ▲ valid set 前 200 筆真實值(藍線)跟預測值(橘線)觀察圖\n ▲ test set 真實值(藍線)跟預測值(橘線)觀察圖，可以看到除了部分超過速限的資料外，整體還行。\n無論是 valid set 還是 test set 的 RMSE 跟繪圖結果，看起來都相當不錯，但實際執行預測下半年的資料後，還是覺得有些問題。"
  },
  {
    "objectID": "posts/side-project1/side-project1.html#模型預測部分",
    "href": "posts/side-project1/side-project1.html#模型預測部分",
    "title": "Side Project - 簡易預估搭乘新竹客運假日從新竹到台中的時間",
    "section": "模型預測部分",
    "text": "模型預測部分\n雖然 LSTM 模型的表現從數據看起來相當不錯，不過實際預測結果的 TravelSpeed 卻經常保持在平穩的線上，這跟我實際搭車的經驗不太符合，細想後我認為有 2 個原因：\n\nTravelSpeed 的定義跟搭乘客運的時速沒有關係\nLSTM 模型適合預測沒有遭遇突發重大變化的資料，反過來說當沒有太大變化的資料時間步細分成數分鐘時，LSTM 模型的預測也不會有太大的變化\n\n其中 1. 可能是主要原因，只能說搞清楚資料定義真的真的很重要QQ"
  },
  {
    "objectID": "posts/side-project1/side-project1.html#uiux-設計",
    "href": "posts/side-project1/side-project1.html#uiux-設計",
    "title": "Side Project - 簡易預估搭乘新竹客運假日從新竹到台中的時間",
    "section": "UIUX 設計",
    "text": "UIUX 設計\n目前將資料部署在 streamlit 平台上，雖然有不用切換程式語言、使用語言直觀簡潔、不用自己重新設計 UIUX 等優點，但實際部署後網路載入速度實在是太慢了，而且也沒有 RWD 設計。再來是日期及時間表單的選擇，原先我希望能顯示只有我已經預測好的時間區間，但實際發現他的日期跟時間套件沒有這樣選，如果要做到我要的效果，可能需要從現有的 streamlit 輸入元件指令中找一個最符合我想像的，再轉換資料型別成 date time 格式以利後續處理資料。"
  }
]